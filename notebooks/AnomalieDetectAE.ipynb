{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4018faf",
   "metadata": {},
   "source": [
    "# TP2 - Détection d'Anomalies (Auto-Encodeurs)\n",
    "\n",
    "Ce notebook charge les données ECG préparées depuis `data/ECG/` et compare deux architectures d'auto-encodeurs (AE) :\n",
    "  1.  Un AE classique (simple).\n",
    "  2.  Un AE débruiteur (Denoising AE).\n",
    "\n",
    " L'entraînement se fait *uniquement* sur les données normales (`X_train`), la recherche de seuil sur les données de validation (`X_val`), et l'évaluation finale sur les données de test (`X_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644ed215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "665ec2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemin du projet racine : C:\\Users\\sebdr\\OneDrive\\Bureau\\sherbrooke\\IFT 599 - Sciences des données\\TP2 Devoir\\git\n",
      "Chargement des données depuis : C:\\Users\\sebdr\\OneDrive\\Bureau\\sherbrooke\\IFT 599 - Sciences des données\\TP2 Devoir\\git\\data\\ECG\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration des Chemins ---\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "DATA_PROCESSED_PATH = PROJECT_ROOT / \"data\" / \"ECG\"\n",
    "PROJECT_FCT = PROJECT_ROOT / \"src\"\n",
    "sys.path.append(str(PROJECT_FCT))\n",
    "\n",
    "print(f\"Chemin du projet racine : {PROJECT_ROOT}\")\n",
    "print(f\"Chargement des données depuis : {DATA_PROCESSED_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f137479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebdr\\anaconda3\\envs\\udes_sd_a25\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules locaux 'models', 'train' et 'utils' chargés avec succès.\n"
     ]
    }
   ],
   "source": [
    "# --- Chargement des modules locaux ---\n",
    "# (Utilise la structure de /src comme PreparationData.ipynb)\n",
    "try:\n",
    "    # Supposons que ces classes/fonctions existent dans src/\n",
    "    from models import Autoencoder, DenoisingAutoencoder \n",
    "    from train import train_autoencoder, train_denoising_autoencoder\n",
    "    from utils import evaluate_model_threshold\n",
    "    print(\"Modules locaux 'models', 'train' et 'utils' chargés avec succès.\")\n",
    "except ImportError:\n",
    "    print(\"Attention: Les fichiers .py de /src n'ont pas été trouvés.\")\n",
    "    print(\"Définition de classes/fonctions de remplacement (placeholders).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "917a8595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données ECG préparées (depuis data/ECG/)...\n"
     ]
    }
   ],
   "source": [
    "# --- Chargement des données ---\n",
    "\n",
    "print(\"Chargement des données ECG préparées (depuis data/ECG/)...\")\n",
    "try:\n",
    "    X_train_scaled = np.load(DATA_PROCESSED_PATH / 'ecg_X_train_scaled.npy')\n",
    "    X_val_scaled = np.load(DATA_PROCESSED_PATH / 'ecg_X_val_scaled.npy')\n",
    "    X_test_scaled = np.load(DATA_PROCESSED_PATH / 'ecg_X_test_scaled.npy')\n",
    "    y_train = np.load(DATA_PROCESSED_PATH / 'ecg_y_train.npy')\n",
    "    y_val = np.load(DATA_PROCESSED_PATH / 'ecg_y_val.npy')\n",
    "    y_test = np.load(DATA_PROCESSED_PATH / 'ecg_y_test.npy')\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERREUR: Fichiers non trouvés dans {DATA_PROCESSED_PATH}\")\n",
    "    print(\"Veuillez d'abord exécuter le notebook 'PreparationData.ipynb'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "827ee4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders PyTorch créés.\n"
     ]
    }
   ],
   "source": [
    "# --- Conversion en Tensors PyTorch ---\n",
    "BATCH_SIZE = 64\n",
    "X_train_t = torch.tensor(X_train_scaled.astype(np.float32))\n",
    "X_val_t = torch.tensor(X_val_scaled.astype(np.float32))\n",
    "X_test_t = torch.tensor(X_test_scaled.astype(np.float32))\n",
    "y_val_t = torch.tensor(y_val.astype(np.float32))\n",
    "y_test_t = torch.tensor(y_test.astype(np.float32))\n",
    "\n",
    "# Dataset (Train ne contient que des données normales)\n",
    "train_dataset = TensorDataset(X_train_t, torch.tensor(y_train.astype(np.float32)))\n",
    "val_dataset = TensorDataset(X_val_t, y_val_t)\n",
    "test_dataset = TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders PyTorch créés.\")\n",
    "input_dim = X_train_scaled.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba4413",
   "metadata": {},
   "source": [
    "# 1. Auto-encodeur (AE) Classique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47b018e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début de l'entraînement (AE) pour 50 époques...\n",
      "Époque [10/50], Perte (Loss): 0.299233\n",
      "Époque [20/50], Perte (Loss): 0.190413\n",
      "Époque [30/50], Perte (Loss): 0.149218\n",
      "Époque [40/50], Perte (Loss): 0.116133\n",
      "Époque [50/50], Perte (Loss): 0.099761\n",
      "Entraînement terminé en 1.97 secondes.\n"
     ]
    }
   ],
   "source": [
    "# --- Entraînement AE ---\n",
    "model_ae = Autoencoder(input_dim)\n",
    "model_ae = train_autoencoder(model_ae, train_loader, n_epochs=50, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20d734ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcul des erreurs et du seuil optimal...\n",
      "Seuil optimal (AE) trouvé: 0.189786 (F1-Score Val: 0.9881)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebdr\\OneDrive\\Bureau\\sherbrooke\\IFT 599 - Sciences des données\\TP2 Devoir\\git\\src\\utils.py:217: RuntimeWarning: invalid value encountered in divide\n",
      "  f1_scores = (2 * precisions * recalls) / (precisions + recalls)\n"
     ]
    }
   ],
   "source": [
    "# --- Seuil AE (sur Validation) ---\n",
    "threshold_ae, f1_val_ae = evaluate_model_threshold(model_ae, val_loader, y_val)\n",
    "print(f\"Seuil optimal (AE) trouvé: {threshold_ae:.6f} (F1-Score Val: {f1_val_ae:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a17b8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation de l'AE Classique sur l'ensemble de test...\n",
      "Accuracy (AE): 0.9733\n",
      "Precision (AE): 0.9720\n",
      "Recall (AE): 0.9949\n",
      "F1-Score (AE): 0.9833\n",
      "ROC-AUC (AE): 0.9448\n",
      "\n",
      "Rapport de Classification (AE) sur Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Normal (0)       0.98      0.89      0.93       624\n",
      "Anomalie (1)       0.97      0.99      0.98      2336\n",
      "\n",
      "    accuracy                           0.97      2960\n",
      "   macro avg       0.98      0.94      0.96      2960\n",
      "weighted avg       0.97      0.97      0.97      2960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Évaluation AE (sur Test) ---\n",
    "print(\"Évaluation de l'AE Classique sur l'ensemble de test...\")\n",
    "model_ae.eval()\n",
    "test_errors_ae = []\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in test_loader:\n",
    "        recon = model_ae(inputs)\n",
    "        errors = torch.mean((inputs - recon) ** 2, dim=1)\n",
    "        test_errors_ae.extend(errors.numpy())\n",
    "\n",
    "y_pred_ae = (np.array(test_errors_ae) > threshold_ae).astype(int) # 1 = Anomalie\n",
    "y_test_np = y_test # Labels réels\n",
    "\n",
    "# --- Métriques de performance (AE) ---\n",
    "accuracy_ae = accuracy_score(y_test_np, y_pred_ae)\n",
    "precision_ae = precision_score(y_test_np, y_pred_ae, pos_label=1)\n",
    "recall_ae = recall_score(y_test_np, y_pred_ae, pos_label=1)\n",
    "f1_ae = f1_score(y_test_np, y_pred_ae, pos_label=1)\n",
    "roc_auc_ae = roc_auc_score(y_test_np, test_errors_ae)\n",
    "\n",
    "print(f\"Accuracy (AE): {accuracy_ae:.4f}\")\n",
    "print(f\"Precision (AE): {precision_ae:.4f}\")\n",
    "print(f\"Recall (AE): {recall_ae:.4f}\")\n",
    "print(f\"F1-Score (AE): {f1_ae:.4f}\")\n",
    "print(f\"ROC-AUC (AE): {roc_auc_ae:.4f}\")\n",
    "print(\"\\nRapport de Classification (AE) sur Test:\")\n",
    "print(classification_report(y_test_np, y_pred_ae, target_names=['Normal (0)', 'Anomalie (1)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5537c92",
   "metadata": {},
   "source": [
    "# 2. Auto-encodeur Débruiteur (DAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10c54071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début de l'entraînement (DAE) pour 50 époques...\n",
      "Époque [10/50], Perte (Loss): 0.316329\n",
      "Époque [20/50], Perte (Loss): 0.189910\n",
      "Époque [30/50], Perte (Loss): 0.155188\n",
      "Époque [40/50], Perte (Loss): 0.136216\n",
      "Époque [50/50], Perte (Loss): 0.111829\n",
      "Entraînement DAE terminé en 2.06 secondes.\n"
     ]
    }
   ],
   "source": [
    "# --- Entraînement DAE ---\n",
    "model_dae = DenoisingAutoencoder(input_dim, noise_factor=0.2)\n",
    "model_dae = train_denoising_autoencoder(model_dae, train_loader, n_epochs=50, lr=1e-3, noise_factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f56f5a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcul des erreurs et du seuil optimal...\n",
      "Seuil optimal (DAE) trouvé: 0.190498 (F1-Score Val: 0.9838)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebdr\\OneDrive\\Bureau\\sherbrooke\\IFT 599 - Sciences des données\\TP2 Devoir\\git\\src\\utils.py:217: RuntimeWarning: invalid value encountered in divide\n",
      "  f1_scores = (2 * precisions * recalls) / (precisions + recalls)\n"
     ]
    }
   ],
   "source": [
    "# --- Seuil DAE (sur Validation) ---\n",
    "threshold_dae, f1_val_dae = evaluate_model_threshold(model_dae, val_loader, y_val)\n",
    "print(f\"Seuil optimal (DAE) trouvé: {threshold_dae:.6f} (F1-Score Val: {f1_val_dae:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3dc459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation du DAE sur l'ensemble de test...\n",
      "Accuracy (DAE): 0.9676\n",
      "Precision (DAE): 0.9718\n",
      "Recall (DAE): 0.9876\n",
      "F1-Score (DAE): 0.9796\n",
      "ROC-AUC (DAE): 0.9430\n",
      "\n",
      "Rapport de Classification (DAE) sur Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Normal (0)       0.95      0.89      0.92       624\n",
      "Anomalie (1)       0.97      0.99      0.98      2336\n",
      "\n",
      "    accuracy                           0.97      2960\n",
      "   macro avg       0.96      0.94      0.95      2960\n",
      "weighted avg       0.97      0.97      0.97      2960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Évaluation DAE (sur Test) ---\n",
    "print(\"Évaluation du DAE sur l'ensemble de test...\")\n",
    "model_dae.eval()\n",
    "test_errors_dae = []\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in test_loader:\n",
    "        recon = model_dae(inputs)\n",
    "        errors = torch.mean((inputs - recon) ** 2, dim=1)\n",
    "        test_errors_dae.extend(errors.numpy())\n",
    "\n",
    "y_pred_dae = (np.array(test_errors_dae) > threshold_dae).astype(int)\n",
    "\n",
    "# --- Métriques de performance (DAE) ---\n",
    "accuracy_dae = accuracy_score(y_test_np, y_pred_dae)\n",
    "precision_dae = precision_score(y_test_np, y_pred_dae, pos_label=1)\n",
    "recall_dae = recall_score(y_test_np, y_pred_dae, pos_label=1)\n",
    "f1_dae = f1_score(y_test_np, y_pred_dae, pos_label=1)\n",
    "roc_auc_dae = roc_auc_score(y_test_np, test_errors_dae)\n",
    "\n",
    "print(f\"Accuracy (DAE): {accuracy_dae:.4f}\")\n",
    "print(f\"Precision (DAE): {precision_dae:.4f}\")\n",
    "print(f\"Recall (DAE): {recall_dae:.4f}\")\n",
    "print(f\"F1-Score (DAE): {f1_dae:.4f}\")\n",
    "print(f\"ROC-AUC (DAE): {roc_auc_dae:.4f}\")\n",
    "print(\"\\nRapport de Classification (DAE) sur Test:\")\n",
    "print(classification_report(y_test_np, y_pred_dae, target_names=['Normal (0)', 'Anomalie (1)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0003cb2d",
   "metadata": {},
   "source": [
    "# 3. Comparaison AE vs DAE (et IF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81f48a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Résultats Isolation Forest reportés---\n",
    "accuracy_if = 0.9622\n",
    "precision_if = 0.9572\n",
    "recall_if = 0.9966\n",
    "f1_if = 0.9765\n",
    "roc_auc_if = 0.9218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15d04736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tableau de Comparaison des Modèles de Détection d'Anomalies (sur X_test) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_65ba6_row0_col2, #T_65ba6_row1_col0, #T_65ba6_row1_col1, #T_65ba6_row1_col3, #T_65ba6_row1_col4 {\n",
       "  background-color: green;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_65ba6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_65ba6_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_65ba6_level0_col1\" class=\"col_heading level0 col1\" >Precision (Anomalie)</th>\n",
       "      <th id=\"T_65ba6_level0_col2\" class=\"col_heading level0 col2\" >Recall (Anomalie)</th>\n",
       "      <th id=\"T_65ba6_level0_col3\" class=\"col_heading level0 col3\" >F1-Score (Anomalie)</th>\n",
       "      <th id=\"T_65ba6_level0_col4\" class=\"col_heading level0 col4\" >ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_65ba6_level0_row0\" class=\"row_heading level0 row0\" >Isolation Forest</th>\n",
       "      <td id=\"T_65ba6_row0_col0\" class=\"data row0 col0\" >0.9622</td>\n",
       "      <td id=\"T_65ba6_row0_col1\" class=\"data row0 col1\" >0.9572</td>\n",
       "      <td id=\"T_65ba6_row0_col2\" class=\"data row0 col2\" >0.9966</td>\n",
       "      <td id=\"T_65ba6_row0_col3\" class=\"data row0 col3\" >0.9765</td>\n",
       "      <td id=\"T_65ba6_row0_col4\" class=\"data row0 col4\" >0.9218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_65ba6_level0_row1\" class=\"row_heading level0 row1\" >Auto-encodeur (AE)</th>\n",
       "      <td id=\"T_65ba6_row1_col0\" class=\"data row1 col0\" >0.9733</td>\n",
       "      <td id=\"T_65ba6_row1_col1\" class=\"data row1 col1\" >0.9720</td>\n",
       "      <td id=\"T_65ba6_row1_col2\" class=\"data row1 col2\" >0.9949</td>\n",
       "      <td id=\"T_65ba6_row1_col3\" class=\"data row1 col3\" >0.9833</td>\n",
       "      <td id=\"T_65ba6_row1_col4\" class=\"data row1 col4\" >0.9448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_65ba6_level0_row2\" class=\"row_heading level0 row2\" >Denoising AE (DAE)</th>\n",
       "      <td id=\"T_65ba6_row2_col0\" class=\"data row2 col0\" >0.9676</td>\n",
       "      <td id=\"T_65ba6_row2_col1\" class=\"data row2 col1\" >0.9718</td>\n",
       "      <td id=\"T_65ba6_row2_col2\" class=\"data row2 col2\" >0.9876</td>\n",
       "      <td id=\"T_65ba6_row2_col3\" class=\"data row2 col3\" >0.9796</td>\n",
       "      <td id=\"T_65ba6_row2_col4\" class=\"data row2 col4\" >0.9430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2548626dc70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_summary = {\n",
    "     \"Isolation Forest\": {\n",
    "         \"Accuracy\": accuracy_if, \"Precision (Anomalie)\": precision_if, \n",
    "         \"Recall (Anomalie)\": recall_if, \"F1-Score (Anomalie)\": f1_if, \"ROC-AUC\": roc_auc_if\n",
    "     },\n",
    "     \"Auto-encodeur (AE)\": {\n",
    "         \"Accuracy\": accuracy_ae, \"Precision (Anomalie)\": precision_ae, \n",
    "         \"Recall (Anomalie)\": recall_ae, \"F1-Score (Anomalie)\": f1_ae, \"ROC-AUC\": roc_auc_ae\n",
    "     },\n",
    "     \"Denoising AE (DAE)\": {\n",
    "         \"Accuracy\": accuracy_dae, \"Precision (Anomalie)\": precision_dae, \n",
    "         \"Recall (Anomalie)\": recall_dae, \"F1-Score (Anomalie)\": f1_dae, \"ROC-AUC\": roc_auc_dae\n",
    "     }\n",
    " }\n",
    " \n",
    "df_anomaly_results = pd.DataFrame(data_summary).T\n",
    "df_anomaly_results_styled = df_anomaly_results.style.format(\"{:.4f}\").highlight_max(axis=0, color='green')\n",
    "print(\"--- Tableau de Comparaison des Modèles de Détection d'Anomalies (sur X_test) ---\")\n",
    "df_anomaly_results_styled"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udes_sd_a25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
