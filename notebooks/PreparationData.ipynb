{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8300ab6",
   "metadata": {},
   "source": [
    "# TP2 - Préparation des Données\n",
    "\n",
    " Ce notebook charge les deux jeux de données (Hi-Seq et ECG), effectue la normalisation nécessaire et sauvegarde les fichiers préparés (`.npy` ou `.csv`) pour qu'ils soient utilisés par les autres notebooks de clustering et de détection d'anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8249978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports de base ---\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd8fcc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemin du projet racine : C:\\Users\\sebdr\\OneDrive\\Bureau\\sherbrooke\\IFT 599 - Sciences des données\\TP2 Devoir\\git\n",
      "Tentative de chargement du fichier : C:\\Users\\sebdr\\OneDrive\\Bureau\\sherbrooke\\IFT 599 - Sciences des données\\TP2 Devoir\\git\\data\n",
      "Sauvegarde vers : ..\\data\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path(\"..\")\n",
    "\n",
    "# --- Chemins des données ---\n",
    "DATA_PATH = PROJECT_ROOT / \"data\"\n",
    "\n",
    "DATA_FILE1 = \"hiseq_data.csv\"\n",
    "DATA_FILE_PATH1 = DATA_PATH / DATA_FILE1\n",
    "\n",
    "DATA_FILE2 = \"hiseq_labels.csv\"\n",
    "DATA_FILE_PATH2 = DATA_PATH / DATA_FILE2\n",
    "\n",
    "# --- Chemin des fonctions utilitaires ---\n",
    "PROJECT_FCT = Path(\"../src\").resolve()\n",
    "sys.path.append(str(PROJECT_FCT))\n",
    "\n",
    "# Chemin des données traitées (en sortie)\n",
    "DATA_PROCESSED_PATH = PROJECT_ROOT / \"data\"\n",
    "\n",
    "print(f\"Chemin du projet racine : {PROJECT_ROOT.resolve()}\")\n",
    "print(f\"Tentative de chargement du fichier : {DATA_PATH.resolve()}\")\n",
    "print(f\"Sauvegarde vers : {DATA_PROCESSED_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca6a8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from utils import load_dataset\n",
    "    from preprocess import normalize_data\n",
    "except ImportError:\n",
    "    print(\"Attention: Les fichiers tp2_utils.py ou tp2_preprocess.py n'ont pas été trouvés.\")\n",
    "    print(\"Définition de fonctions de remplacement.\")\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68931286",
   "metadata": {},
   "source": [
    "# 1. Préparation des données Hi-Seq (Clustering)\n",
    "\n",
    " - Chargement des données et des étiquettes (vérité terrain).\n",
    " - Normalisation (StandardScaler).\n",
    " - Sauvegarde de `X_scaled` et `y` pour les notebooks de clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f37f2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données Hi-Seq data\n",
      "Données Hi-Seq chargées, forme de X: (801, 20531)\n",
      "Chargement des données Hi-Seq labels\n",
      "Données Hi-Seq labels chargées, forme de y: (801, 1)\n",
      "Forme de X_hiseq: (801, 20531)\n",
      "Forme de y_hiseq: (801,)\n"
     ]
    }
   ],
   "source": [
    "# Charger les données \n",
    "X_hiseq, y_hiseq = load_dataset(DATA_FILE_PATH1, DATA_FILE_PATH2)\n",
    "\n",
    "print(f\"Forme de X_hiseq: {X_hiseq.shape}\")\n",
    "print(f\"Forme de y_hiseq: {y_hiseq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7350110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisation des données avec StandardScaler...\n"
     ]
    }
   ],
   "source": [
    "# --- Normalisation Hi-Seq ---\n",
    "X_hiseq_scaled = normalize_data(X_hiseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af21c4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sauvegarde des fichiers Hi-Seq normalisés dans ..\\data...\n",
      "Terminé.\n"
     ]
    }
   ],
   "source": [
    "# --- Sauvegarde Hi-Seq ---\n",
    "print(f\"Sauvegarde des fichiers Hi-Seq normalisés dans {DATA_PROCESSED_PATH}...\")\n",
    "\n",
    "# Utilise le chemin de sortie pour la sauvegarde\n",
    "np.save(DATA_PROCESSED_PATH / 'hiseq_X_scaled.npy', X_hiseq_scaled)\n",
    "y_hiseq.to_csv(DATA_PROCESSED_PATH / 'hiseq_y_labels.csv', header=True)\n",
    "\n",
    "print(\"Terminé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63169bd",
   "metadata": {},
   "source": [
    "# 2. Préparation des données ECG (Détection d'Anomalies)\n",
    "\n",
    " - Chargement des données ECG.\n",
    " - Séparation des données normales (0) et anormales (1).\n",
    " - Création des ensembles:\n",
    "    - `Train` : 60% des données normales (pour l'entraînement des modèles).\n",
    "    - `Validation` : 10% des normales + 20% des anormales (pour trouver le seuil).\n",
    "    - `Test` : 30% des normales + 80% des anormales (pour l'évaluation finale).\n",
    " - Normalisation (StandardScaler) *entraîné seulement sur `X_train`*.\n",
    " - Sauvegarde des 6 fichiers (`X_train_scaled`, `y_train`, `X_val_scaled`, `y_val`, `X_test_scaled`, `y_test`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udes_sd_a25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
