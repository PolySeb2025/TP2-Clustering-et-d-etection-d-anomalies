{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8300ab6",
   "metadata": {},
   "source": [
    "# TP2 - Préparation des Données\n",
    "\n",
    " Ce notebook charge les deux jeux de données (Hi-Seq et ECG), effectue la normalisation nécessaire et sauvegarde les fichiers préparés (`.npy` ou `.csv`) pour qu'ils soient utilisés par les autres notebooks de clustering et de détection d'anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8249978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports de base ---\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd8fcc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemin du projet racine : C:\\Users\\sebdr\\OneDrive\\Bureau\\sherbrooke\\IFT 599 - Sciences des données\\TP2 Devoir\\git\n",
      "Tentative de chargement du fichier : C:\\Users\\sebdr\\OneDrive\\Bureau\\sherbrooke\\IFT 599 - Sciences des données\\TP2 Devoir\\git\\data\n",
      "Sauvegarde vers : ..\\data\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path(\"..\")\n",
    "\n",
    "# --- Chemins des données ---\n",
    "DATA_PATH = PROJECT_ROOT / \"data\"\n",
    "\n",
    "DATA_FILE1 = \"hiseq_data.csv\"\n",
    "DATA_FILE_PATH1 = DATA_PATH / DATA_FILE1\n",
    "\n",
    "DATA_FILE2 = \"hiseq_labels.csv\"\n",
    "DATA_FILE_PATH2 = DATA_PATH / DATA_FILE2\n",
    "\n",
    "# --- Chemin des fonctions utilitaires ---\n",
    "PROJECT_FCT = Path(\"../src\").resolve()\n",
    "sys.path.append(str(PROJECT_FCT))\n",
    "\n",
    "# Chemin des données traitées (en sortie)\n",
    "DATA_PROCESSED_PATH = PROJECT_ROOT / \"data\"\n",
    "\n",
    "print(f\"Chemin du projet racine : {PROJECT_ROOT.resolve()}\")\n",
    "print(f\"Tentative de chargement du fichier : {DATA_PATH.resolve()}\")\n",
    "print(f\"Sauvegarde vers : {DATA_PROCESSED_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca6a8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from utils import load_dataset\n",
    "    from preprocess import normalize_data\n",
    "except ImportError:\n",
    "    print(\"Attention: Les fichiers tp2_utils.py ou tp2_preprocess.py n'ont pas été trouvés.\")\n",
    "    print(\"Définition de fonctions de remplacement.\")\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68931286",
   "metadata": {},
   "source": [
    "# 1. Préparation des données Hi-Seq (Clustering)\n",
    "\n",
    " - Chargement des données et des étiquettes (vérité terrain).\n",
    " - Normalisation (StandardScaler).\n",
    " - Sauvegarde de `X_scaled` et `y` pour les notebooks de clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f37f2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données Hi-Seq data\n",
      "Données Hi-Seq chargées, forme de X: (801, 20531)\n",
      "Chargement des données Hi-Seq labels\n",
      "Données Hi-Seq labels chargées, forme de y: (801, 1)\n",
      "Forme de X_hiseq: (801, 20531)\n",
      "Forme de y_hiseq: (801,)\n"
     ]
    }
   ],
   "source": [
    "# Charger les données \n",
    "X_hiseq, y_hiseq = load_dataset(DATA_FILE_PATH1, DATA_FILE_PATH2)\n",
    "\n",
    "print(f\"Forme de X_hiseq: {X_hiseq.shape}\")\n",
    "print(f\"Forme de y_hiseq: {y_hiseq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7350110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisation des données avec StandardScaler...\n"
     ]
    }
   ],
   "source": [
    "# --- Normalisation Hi-Seq ---\n",
    "X_hiseq_scaled = normalize_data(X_hiseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af21c4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sauvegarde des fichiers Hi-Seq normalisés dans ..\\data...\n",
      "Terminé.\n"
     ]
    }
   ],
   "source": [
    "# --- Sauvegarde Hi-Seq ---\n",
    "print(f\"Sauvegarde des fichiers Hi-Seq normalisés dans {DATA_PROCESSED_PATH}...\")\n",
    "\n",
    "# Utilise le chemin de sortie pour la sauvegarde\n",
    "np.save(DATA_PROCESSED_PATH / 'hiseq_X_scaled.npy', X_hiseq_scaled)\n",
    "y_hiseq.to_csv(DATA_PROCESSED_PATH / 'hiseq_y_labels.csv', header=True)\n",
    "\n",
    "print(\"Terminé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63169bd",
   "metadata": {},
   "source": [
    "# 2. Préparation des données ECG (Détection d'Anomalies)\n",
    "\n",
    " - Chargement des données ECG = Électrocardiogramme.\n",
    " - Séparation des données normales (0) et anormales (1).\n",
    " - Création des ensembles:\n",
    "    - `Train` : 60% des données normales (pour l'entraînement des modèles).\n",
    "    - `Validation` : 10% des normales + 20% des anormales (pour trouver le seuil).\n",
    "    - `Test` : 30% des normales + 80% des anormales (pour l'évaluation finale).\n",
    " - Normalisation (StandardScaler) *entraîné seulement sur `X_train`*.\n",
    " - Sauvegarde des 6 fichiers (`X_train_scaled`, `y_train`, `X_val_scaled`, `y_val`, `X_test_scaled`, `y_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "036d4ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du jeu de données ..\\data\\ecg.npz...\n",
      "Données ECG chargées. Forme totale: (4998, 141)\n"
     ]
    }
   ],
   "source": [
    "# --- Chargement ECG ---\n",
    "ECG_DATA_FILE = DATA_PATH / 'ecg.npz'\n",
    "\n",
    "print(f\"Chargement du jeu de données {ECG_DATA_FILE}...\")\n",
    "data_ecg = np.load(ECG_DATA_FILE)\n",
    "df_ecg_full = pd.DataFrame(data_ecg['ecg'])\n",
    "\n",
    "# Renommage des colonnes (140 features, 1 label)\n",
    "feature_cols = [f'feature_{i}' for i in range(df_ecg_full.shape[1] - 1)]\n",
    "df_ecg_full.columns = feature_cols + ['label']\n",
    "df_ecg_full['label'] = df_ecg_full['label'].astype(int)\n",
    "\n",
    "print(f\"Données ECG chargées. Forme totale: {df_ecg_full.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f83c5325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Division Train/Val/Test terminée.\n"
     ]
    }
   ],
   "source": [
    "# --- Division des données ECG ---\n",
    "df_normal = df_ecg_full[df_ecg_full['label'] == 0]\n",
    "df_anomaly = df_ecg_full[df_ecg_full['label'] == 1]\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Division des données NORMALES (60% train, 10% val, 30% test)\n",
    "normal_train, normal_temp = train_test_split(df_normal, test_size=0.4, random_state=RANDOM_SEED)\n",
    "normal_val, normal_test = train_test_split(normal_temp, test_size=0.75, random_state=RANDOM_SEED)\n",
    "\n",
    "# Division des données ANORMALES (20% val, 80% test)\n",
    "anomaly_val, anomaly_test = train_test_split(df_anomaly, test_size=0.8, random_state=RANDOM_SEED)\n",
    "\n",
    "# Combinaison\n",
    "df_train = normal_train\n",
    "df_val = pd.concat([normal_val, anomaly_val])\n",
    "df_test = pd.concat([normal_test, anomaly_test])\n",
    "\n",
    "# Séparation X/y\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train['label']\n",
    "X_val = df_val[feature_cols]\n",
    "y_val = df_val['label']\n",
    "X_test = df_test[feature_cols]\n",
    "y_test = df_test['label']\n",
    "\n",
    "print(\"Division Train/Val/Test terminée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "539ad030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisation des ensembles ECG...\n",
      "Normalisation terminée.\n"
     ]
    }
   ],
   "source": [
    "# --- Normalisation ECG ---\n",
    "print(\"Normalisation des ensembles ECG...\")\n",
    "scaler_ecg = StandardScaler()\n",
    "X_train_scaled = scaler_ecg.fit_transform(X_train)\n",
    "X_val_scaled = scaler_ecg.transform(X_val)\n",
    "X_test_scaled = scaler_ecg.transform(X_test)\n",
    "\n",
    "print(\"Normalisation terminée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9914361d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sauvegarde des fichiers ECG préparés dans ..\\data...\n",
      "Terminé.\n"
     ]
    }
   ],
   "source": [
    "# --- Sauvegarde ECG ---\n",
    "print(f\"Sauvegarde des fichiers ECG préparés dans {DATA_PROCESSED_PATH}...\")\n",
    "\n",
    "np.save(DATA_PROCESSED_PATH / 'ecg_X_train_scaled.npy', X_train_scaled)\n",
    "np.save(DATA_PROCESSED_PATH / 'ecg_X_val_scaled.npy', X_val_scaled)\n",
    "np.save(DATA_PROCESSED_PATH / 'ecg_X_test_scaled.npy', X_test_scaled)\n",
    "np.save(DATA_PROCESSED_PATH / 'ecg_y_train.npy', y_train.values)\n",
    "np.save(DATA_PROCESSED_PATH / 'ecg_y_val.npy', y_val.values)\n",
    "np.save(DATA_PROCESSED_PATH / 'ecg_y_test.npy', y_test.values)\n",
    "\n",
    "print(\"Terminé.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udes_sd_a25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
